{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import os, alive_progress\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "from utils import VD_A as vda\n",
    "from utils import apfd\n",
    "from utils import cartesian\n",
    "from utils import derive_data\n",
    "from utils import sort_vda\n",
    "from utils import calc_s12\n",
    "\n",
    "def _interp_addsorted(alist, datapoints=[]):\n",
    "    cc_dp = alist.copy()\n",
    "    for newdp in datapoints:\n",
    "        if(newdp in cc_dp): continue\n",
    "        cc_dp = np.insert(cc_dp,np.searchsorted(cc_dp,newdp),newdp)\n",
    "    return cc_dp\n",
    "\n",
    "def interp(data: pd.DataFrame.dtypes, col_costs: str, col_hypsizes: str, datapoints=[]):\n",
    "    df_subset = data.copy()\n",
    "    df_subset[col_hypsizes+'_withdatapoints']=df_subset[col_hypsizes].apply(lambda x: _interp_addsorted(x,datapoints))\n",
    "    df_subset[col_costs]=df_subset.apply(lambda x: np.interp(x[col_hypsizes+'_withdatapoints'], x[col_hypsizes], x[col_costs]),axis=1)\n",
    "    df_subset[col_hypsizes]=df_subset[col_hypsizes+'_withdatapoints']\n",
    "    df_subset.drop(col_hypsizes+'_withdatapoints',inplace=True,axis=1)\n",
    "    return df_subset\n",
    "\n",
    "\n",
    "# set inline print\n",
    "%matplotlib inline\n",
    "\n",
    "os.makedirs(f'data/img/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV, calculate APFD and filter Equivalent==OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixed = pd.concat([pd.read_csv(os.path.join(pth)) for pth in [\"k_1_k_2_hads_hsi_w_wp_h_fixed.csv\", \"k_1_k_2_spy_spyh.csv\"]])\n",
    "df_fixed = derive_data(df_fixed)\n",
    "df_fixed.EquivalenceOracle=df_fixed.CTT\n",
    "df_fixed['Type'] = 'Fixed'\n",
    "\n",
    "df_random = pd.read_csv(os.path.join(\"random_logs.csv\"))\n",
    "df_random = derive_data(df_random)\n",
    "df_random.EquivalenceOracle=df_random.apply(lambda x: x.CTT+','+str(x['Random Infix Length']), axis=1)\n",
    "df_random['Type'] = 'Random'\n",
    "df_random['EquivalenceOracle'] = pd.Categorical(df_random['EquivalenceOracle'], \n",
    "  [f'{x[0]},{x[1]}' for x in list(cartesian(([\"HadsInt\", \"Hsi\", \"Wp\", \"W\"], df_random['Random Infix Length'].unique()))\n",
    ")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate dataframes and derive AFPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivs_drv = pd.concat([df_fixed])\n",
    "equivs_drv = pd.concat([df_fixed,df_random])\n",
    "equivs_drv = pd.merge(equivs_drv, pd.read_csv(os.path.join(\"SUL_list.csv\")), how='left',on='SUL name')\n",
    "equivs_drv = equivs_drv.query(f'`Equivalent`==\"OK\" and `Extra States`==2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot %states detected per test case (for all methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting APFD |████████████████████████████████████████| 46/46 [100%] in 1:08.2 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3200x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define figure DPI\n",
    "sns.set(rc={'figure.dpi':400})\n",
    "\n",
    "all_runs = equivs_drv[['SUL name']].drop_duplicates()\n",
    "# all_runs = equivs_drv.query(f'`SUL name`in [\"TCP_Linux_Client.dot\"]')[['SUL name']].drop_duplicates()\n",
    "total = len(all_runs)\n",
    "\n",
    "new_dps = list(range(10,101,10))\n",
    "new_dps.reverse()\n",
    "\n",
    "# methods = [\"W\", \"Wp\", \"SPY\", \"HadsInt\"]\n",
    "methods = [\"W\", \"Wp\", \"Hsi\", \"H\", \"SPY\", \"SPYH\", \"HadsInt\"]\n",
    "with alive_bar(total, force_tty=True, title=f'Plotting APFD') as bar:\n",
    "    for idx,row in all_runs.iterrows():\n",
    "        # get an entry <SUL, seed>\n",
    "        sulname = row['SUL name']\n",
    "        fname=sulname.replace('.dot','')\n",
    "        subj=equivs_drv.query(f'`SUL name`==\"{sulname}\" and `Type`==\"Fixed\" and `CTT` in @methods').copy()\n",
    "        \n",
    "        apfd_tab = subj[['CTT','MQ','EQ','TC','Rounds','APFD']].sort_values(['APFD'],ascending=False)\n",
    "        apfd_tab.to_csv(f'data/img/{fname}.csv')\n",
    "        \n",
    "        # add percent columns\n",
    "        subj['HypSizePercent'] = subj['HypSize'].apply(lambda x: x/np.max(x)*100)\n",
    "\n",
    "        # analyze qtype column \n",
    "        qtype = 'Total cost'\n",
    "        \n",
    "        subj_interp=interp(data=subj, col_costs=qtype,col_hypsizes='HypSizePercent', datapoints=new_dps)\n",
    "        subj_interp=subj_interp.explode(['HypSizePercent',qtype])\n",
    "        subj_interp=subj_interp.query('HypSizePercent in @new_dps').sort_values(by=[qtype],ascending=False)\n",
    "\n",
    "        cols_order = subj_interp['CTT'].drop_duplicates().to_list()\n",
    "        cols_order.reverse()\n",
    "\n",
    "        the_cols = ['SUL name','HypSizePercent','CTT']\n",
    "        subj_gb=subj_interp[[*the_cols,qtype]].groupby(the_cols).first()\n",
    "\n",
    "        subj_pvt = subj_gb.pivot_table(qtype,['CTT'],'HypSizePercent').sort_values(by=list(new_dps))\n",
    "        #subj_pvt = subj_pvt/subj_pvt.max().max()\n",
    "        heatmap_cost=sns.heatmap(subj_pvt,\n",
    "                         annot=True, fmt=\",.0f\", annot_kws={'rotation': 0, 'fontsize':9}, \n",
    "                         cmap= sns.cm.rocket_r, linewidth=.5, linecolor='black'\n",
    "                        )\n",
    "\n",
    "        #add plot labels, titles and legends\n",
    "        plt.xlabel('Fraction of the SUL learned')\n",
    "        plt.ylabel('')\n",
    "        #plt.legend(title='Testing Technique', loc='lower right')\n",
    "        plt.title(f'Interpolation of {qtype}')\n",
    "\n",
    "        # save line chart\n",
    "        fig = heatmap_cost.get_figure()\n",
    "        plt.gcf().set_size_inches(30,20)\n",
    "        fig.savefig(f'data/img/{fname}_heatmap.pdf', bbox_inches='tight')\n",
    "        fig.clf()\n",
    "        \n",
    "        # explode qtype column with % of cost and hypothesis sizes in the learning process\n",
    "        subj=subj.explode(['HypSizePercent',qtype])\n",
    "        subj[[*the_cols,qtype]].to_csv(f'data/img/{fname}_HypSizePercent.csv')\n",
    "\n",
    "        #create line chart\n",
    "        apfd_plot = sns.lineplot(subj, x=f'{qtype}', y='HypSizePercent',\n",
    "                                 markers=True, \n",
    "                                 style='CTT', hue='CTT',\n",
    "                                 palette='tab10'\n",
    "                                )\n",
    "        apfd_plot.set(xscale='linear', yscale='linear')\n",
    "        apfd_plot.xaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=True,useOffset=True, useLocale=True))\n",
    "        apfd_plot.yaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "        \n",
    "        #add plot labels, titles and legends\n",
    "        plt.xlabel(f'{qtype.title()}')\n",
    "        plt.ylabel('')\n",
    "        _sulname=sulname.replace('.dot','')\n",
    "        plt.title(f'Subject: {_sulname}\\nFraction of the SUL learned vs. {qtype}')\n",
    "\n",
    "        #get handles and labels\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "        #specify order of items in legend from APFD\n",
    "        order = subj[['CTT','APFD']].sort_values(['APFD'],ascending=False).drop_duplicates().CTT.to_list()\n",
    "        for idx,ctt in enumerate(order): order[idx]=labels.index(ctt)\n",
    "        #add legend to plot\n",
    "        plt.legend([handles[idx] for idx in order],[labels[idx] for idx in order],\n",
    "                   title='Testing Technique', loc='lower right', \n",
    "                   fontsize='xx-small', title_fontsize='xx-small')\n",
    "\n",
    "        # save line chart\n",
    "        fig = apfd_plot.get_figure()\n",
    "        plt.gcf().set_size_inches(8,5)\n",
    "        fig.savefig(f'data/img/{fname}.pdf', bbox_inches='tight')\n",
    "        fig.clf()\n",
    "        \n",
    "        bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw boxplots for TC and APFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4800x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_of_metrics = {'s1':['TC_s1', 'APFD_s1'], 'normalized':['TC_s2', 'APFD_s1']}\n",
    "\n",
    "for ctt_mode in equivs_drv.Type.unique():\n",
    "    dataset = equivs_drv.query(f'`Type`==\"{ctt_mode}\"')\n",
    "    metrics_s12 = calc_s12(dataset).reset_index()\n",
    "    for metric_name,metrics_to_plot in dict_of_metrics.items():\n",
    "        # initialize figure with 2 subplots in a row\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(12,3), dpi=400)\n",
    "\n",
    "        # add padding between the subplots\n",
    "        plt.subplots_adjust(wspace=0.2,hspace=0.3)\n",
    "\n",
    "        idx_inc=0\n",
    "        for metric in metrics_to_plot:\n",
    "            idx=idx_inc\n",
    "            # draw plots\n",
    "            sns.boxplot(data=metrics_s12, ax=ax[idx], x='EquivalenceOracle',y=metric)\n",
    "            ax[idx].set_xlabel('')\n",
    "            ax[idx].set_ylabel(metric.replace(f'_{metric_name}',''))\n",
    "            #ax[idx].set_xlim([0,1])\n",
    "            ax[idx].tick_params(axis='x', rotation=0, labelsize=8)\n",
    "            if \"_s1\" in metric and not \"APFD_\" in metric: ax[idx].set(yscale='log')\n",
    "            idx_inc=idx_inc+1\n",
    "        ##add overall title to replot\n",
    "        #fig.suptitle(f'{ctt_mode} mode')\n",
    "        \n",
    "        # save line chart\n",
    "        fig.savefig(f'data/{ctt_mode}_{metric_name}.pdf', bbox_inches='tight')\n",
    "        fig.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write tables for TC and APFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in equivs_drv.Type.unique():\n",
    "    dataset = equivs_drv.query(f'`Type`==\"{name}\"')\\\n",
    "                .sort_values(['SUL name','EquivalenceOracle','Seed'])\\\n",
    "                .copy()\n",
    "    metrics_s12 = calc_s12(dataset).reset_index()\n",
    "    for metric_name,metrics_to_plot in dict_of_metrics.items():\n",
    "        for metric in metrics_to_plot:\n",
    "            results=metrics_s12.sort_values(['SUL name','EquivalenceOracle'])\\\n",
    "                        .groupby(['EquivalenceOracle'])\\\n",
    "                        .apply(lambda x: x[metric].tolist())\\\n",
    "                        .reset_index().sort_values(['EquivalenceOracle'],ascending=False)\n",
    "            results=results.reindex(index=results.index[::-1])\n",
    "            # apply combination method\n",
    "            results = dict(zip(list(combinations(results['EquivalenceOracle'], 2)),list(combinations(results[0], 2))))\n",
    "            results = pd.DataFrame.from_dict(results, orient='index').reset_index()\n",
    "            results['mwu'] = results.apply(lambda x: mwu(x[0],x[1]).pvalue,axis=1)\n",
    "            results['mwu<0.05'] = results['mwu']<0.05\n",
    "            results[['vda_estimate','vda_magnitude']] = results.apply(lambda x: pd.Series(vda(x[0],x[1])),axis=1)\n",
    "            results[['A','B']] = results['index'].apply(lambda x: pd.Series([x[0],x[1]]))\n",
    "            results.drop([0,1,'index'],axis=1,inplace=True)\n",
    "            results.set_index(['A','B'],inplace=True)\n",
    "            results.columns.name = f'{metric} ({name})'\n",
    "            results.to_csv(f'data/{metric}_{name}.csv', float_format='%.4f')\n",
    "            results.style.to_latex(f'data/{metric}_{name}.tex', column_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}