{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import alive_progress\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "# # set inline print\n",
    "# %matplotlib inline\n",
    "\n",
    "rootdir = os.path.join(\".\")\n",
    "path_logs = os.path.join(rootdir,\"learning_logs.csv\")\n",
    "\n",
    "def apfd(nqueries: list, hypsize: list, max_nqueries=None):\n",
    "    hs = hypsize\n",
    "    nq = nqueries\n",
    "    assert hs[0] == 1\n",
    "    assert len(nq) == len(hs)\n",
    "    \n",
    "    extra_nqueries, extra_hs = [],[]\n",
    "    if(not max_nqueries is None): \n",
    "        extra_nqueries = [max_nqueries]\n",
    "        extra_hs = [hs[-1]]\n",
    "\n",
    "    return 1 - (np.sum(np.multiply([*nq,*extra_nqueries], np.diff([0, *hs,*extra_hs]))) / (np.max([*nq,*extra_nqueries]) * np.max(hs))) + (1.0 / (2 * np.max([*nq,*extra_nqueries])))\n",
    "\n",
    "def auc_learning(nqueries: list, hypsize: list, max_nqueries=None):\n",
    "    hs = hypsize\n",
    "    nq = nqueries\n",
    "    assert hs[0] == 1\n",
    "    assert len(nq) == len(hs)\n",
    "    \n",
    "    extra_nqueries, extra_hs = [],[]\n",
    "    if(not max_nqueries is None): \n",
    "        extra_nqueries = [max_nqueries]\n",
    "        extra_hs = [hs[-1]]\n",
    "    \n",
    "    return np.trapz([*hs,*extra_hs],[*nq,*extra_nqueries])\n",
    "\n",
    "def derive_data(data_frame: pd.DataFrame.dtypes):\n",
    "    # first, copy dataframe\n",
    "    df = data_frame.copy()\n",
    "    \n",
    "    # ...start by concatenating CTT name with number of extra states\n",
    "    df['CTT_ES']  = df['CTT']+\"(\"+df['Extra States'].astype(str)+\")\"\n",
    "    \n",
    "    # ... and then split queries/symbols into different columns\n",
    "    for qtype in [\"Learning\", \"Testing\"]:\n",
    "        _lst= df[f\"{qtype} queries/symbols\"].apply(lambda x: [i.split('/') for i in ast.literal_eval(x)])\n",
    "        df[f\"{qtype} queries\"]            = _lst.apply(lambda x : np.cumsum([int(i[0]) for i in x])) # resets\n",
    "        df[f\"{qtype} symbols\"]            = _lst.apply(lambda x : np.cumsum([int(i[1]) for i in x])) # symbols w/o resets\n",
    "\n",
    "    # ... and then parsing string with hypotheses sizes as array of integers\n",
    "    df[\"HypSize\"] = df[\"HypSize\"].apply(lambda x: ast.literal_eval(x)) \n",
    "    df[\"TQ [Symbols]\"] = df[\"EQ [Symbols]\"]+df[\"MQ [Symbols]\"]\n",
    "    df[\"TQ [Resets]\"] = df[\"EQ [Resets]\"]+df[\"MQ [Resets]\"]\n",
    "\n",
    "    # ... and then append qSize to HypSize, if the run is successfull \n",
    "    df[\"HypSize\"] = df.apply(lambda x: x.HypSize + [x.Qsize] if x.Equivalent=='OK' and len(x.HypSize) < x.Rounds else x.HypSize, axis=1)\n",
    "    \n",
    "    # ... and then include #EQs from the single-state model\n",
    "    df[\"Testing queries\"] = df[\"Testing queries\"].apply(lambda x: [0,*x])\n",
    "    df[\"Testing symbols\"] = df[\"Testing symbols\"].apply(lambda x: [0,*x])\n",
    "    \n",
    "    # ... and then calculate the total number of queries\n",
    "    df[\"Total queries\"] = df.apply(lambda x: np.add(x[\"Testing queries\"],x[\"Learning queries\"]) if x.Equivalent=='OK' else [], axis=1)\n",
    "    df[\"Total symbols\"] = df.apply(lambda x: np.add(x[\"Testing symbols\"],x[\"Learning symbols\"]) if x.Equivalent=='OK' else [], axis=1)\n",
    "    \n",
    "    # ... and then (FINALLY!) calculate the APFD and AUC for EQs, and TQs\n",
    "    df_eq = df.query('`Equivalent`==\"OK\"')\n",
    "    \n",
    "    the_cols = [\"SUL name\",\"TQ [Symbols]\",\"EQ [Symbols]\"]\n",
    "    max_eqs = df[the_cols].groupby([\"SUL name\"]).max().to_dict()\n",
    "\n",
    "    df[\"APFD_testing\"] = df.apply(lambda x: apfd(x['Testing symbols'],x['HypSize']) if x.Equivalent=='OK' else -1, axis=1)\n",
    "    df[\"APFD_total\"] = df.apply(lambda x: apfd(x['Total symbols'],x['HypSize']) if x.Equivalent=='OK' else -1, axis=1)\n",
    "    \n",
    "    df[\"APFDx_testing\"] = df.apply(lambda x: apfd(x['Testing symbols'],x['HypSize'],max_nqueries=max_eqs['EQ [Symbols]'][x['SUL name']]) if x.Equivalent=='OK' else -1, axis=1)\n",
    "    df[\"APFDx_total\"] = df.apply(lambda x: apfd(x['Total symbols'],x['HypSize'],max_nqueries=max_eqs['TQ [Symbols]'][x['SUL name']]) if x.Equivalent=='OK' else -1, axis=1)\n",
    "    \n",
    "    df[\"AUC_testing\"] = df.apply(lambda x: auc_learning(x['Testing symbols'],x['HypSize'],max_nqueries=max_eqs['EQ [Symbols]'][x['SUL name']]) if x.Equivalent=='OK' else -1, axis=1)\n",
    "    df[\"AUC_total\"] = df.apply(lambda x: auc_learning(x['Total symbols'],x['HypSize'],max_nqueries=max_eqs['TQ [Symbols]'][x['SUL name']]) if x.Equivalent=='OK' else -1, axis=1)\n",
    "    \n",
    "    # to close, return the new dataframe with derived columns\n",
    "    return df\n",
    "\n",
    "def _interp_addsorted(alist, datapoints=[]):\n",
    "    cc_dp = alist.copy()\n",
    "    for newdp in datapoints:\n",
    "        if(newdp in cc_dp): continue\n",
    "        cc_dp = np.insert(cc_dp,np.searchsorted(cc_dp,newdp),newdp)\n",
    "    return cc_dp\n",
    "\n",
    "def interp(data: pd.DataFrame.dtypes, col_costs: str, col_hypsizes: str, datapoints=[]):\n",
    "    df_subset = data.copy()\n",
    "    df_subset[col_hypsizes+'_withdatapoints']=df_subset[col_hypsizes].apply(lambda x: _interp_addsorted(x,datapoints))\n",
    "    df_subset[col_costs]=df_subset.apply(lambda x: np.interp(x[col_hypsizes+'_withdatapoints'], x[col_hypsizes], x[col_costs]),axis=1)\n",
    "    df_subset[col_hypsizes]=df_subset[col_hypsizes+'_withdatapoints']\n",
    "    df_subset.drop(col_hypsizes+'_withdatapoints',inplace=True,axis=1)\n",
    "    return df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the CSV file and derive new columns for APFD, APFDx, and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_logs)\n",
    "df = derive_data(df)\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the list of SULs to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equiv=df.query(f'`Equivalent`==\"OK\"').sort_values(by=['APFDx_testing'],ascending=False)\n",
    "\n",
    "all_qtype = ['Testing symbols', 'Total symbols', 'Testing queries', 'Total queries'] \n",
    "# all_qtype = ['Testing symbols'] # alternative\n",
    "all_sulname = df['SUL name'].drop_duplicates().sort_values()\n",
    "total = len(all_qtype)*len(all_sulname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot %states detected per test case (for all methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting APFD |████████████████████████████████████████| 184/184 [100%] in 1:14.5 (2.47/s)                              \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define figure size\n",
    "sns.set(rc={'figure.figsize':(10,5),'figure.dpi':200})\n",
    "\n",
    "with alive_bar(total, force_tty=True, title=f'Plotting APFD') as bar:\n",
    "    for qtype in all_qtype:\n",
    "        for sulname in all_sulname:\n",
    "            # get one entry\n",
    "            subj=df_equiv.query(f'`SUL name`==\"{sulname}\"').copy() \n",
    "\n",
    "            # add percent columns\n",
    "            subj['HypSizePercent'] = subj['HypSize'].apply(lambda x: x/np.max(x)*100)\n",
    "\n",
    "            # explode column with % of symbols and hypothesis sizes in the learning process\n",
    "            subj=subj.explode(['HypSizePercent',f'{qtype}'])\n",
    "\n",
    "            #create line chart\n",
    "            apfd_plot = sns.lineplot(subj, x=f'{qtype}', y='HypSizePercent',\n",
    "                                     markers=True, \n",
    "                                     #style='Extra States', hue='CTT',\n",
    "                                     style='CTT_ES', hue='CTT_ES',\n",
    "                                     palette='rocket'\n",
    "                                    )\n",
    "            apfd_plot.set(xscale='log')\n",
    "            locator = ticker.LogLocator()\n",
    "            locator.MAXTICKS = np.max(subj[f'{qtype}'])\n",
    "            apfd_plot.xaxis.set_major_locator(locator)\n",
    "\n",
    "            apfd_plot.yaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "            apfd_plot.set_ylim(0,100)\n",
    "\n",
    "            #add plot labels, titles and legends\n",
    "            plt.xlabel(f'Number of {qtype}')\n",
    "            plt.ylabel('Fraction of the SUL learned')\n",
    "            plt.legend(title='Testing Technique', loc='lower right')\n",
    "            plt.title(f'Subject: {sulname}')\n",
    "\n",
    "            # save line chart\n",
    "            fig = apfd_plot.get_figure()\n",
    "            os.makedirs(f'img/cumulative/{qtype}/', exist_ok=True)\n",
    "            fig.savefig(f'img/cumulative/{qtype}/'+sulname.replace('.dot',f'_cumulative_{qtype}.jpg'))\n",
    "            fig.clf()\n",
    "            bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot heatmap of #test required to detect %states (for all methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting heatmaps |████████████████████████████████████████| 184/184 [100%] in 49.6s (3.71/s)                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define figure size\n",
    "sns.set(rc={'figure.figsize':(20,5)})\n",
    "\n",
    "# define datapoints to interpolate \n",
    "new_dps = list(range(10,101,5))\n",
    "with alive_bar(total, force_tty=True, title=f'Plotting heatmaps') as bar:\n",
    "    for qtype in all_qtype:\n",
    "        #print(qtype)\n",
    "        for sulname in all_sulname:\n",
    "            #print('\\t',sulname)\n",
    "            # get one entry\n",
    "            subj=df_equiv.query(f'`SUL name`==\"{sulname}\"').copy() \n",
    "\n",
    "            # add percent columns\n",
    "            subj['HypSizePercent'] = subj['HypSize'].apply(lambda x: x/np.max(x)*100)\n",
    "\n",
    "            subj_interp=interp(data=subj, col_costs=f'{qtype}',col_hypsizes='HypSizePercent', datapoints=new_dps)\n",
    "            subj_interp=subj_interp.explode([f'{qtype}','HypSizePercent'])\n",
    "            subj_interp=subj_interp.query('HypSizePercent in @new_dps').sort_values(by=[f'{qtype}'],ascending=False)\n",
    "\n",
    "            cols_order = subj_interp['CTT_ES'].drop_duplicates().to_list()\n",
    "            cols_order.reverse()\n",
    "\n",
    "            the_cols = ['SUL name','HypSizePercent','CTT_ES']\n",
    "            subj_gb=subj_interp[the_cols+[f'{qtype}',]].groupby(the_cols).first()\n",
    "\n",
    "            ## The scope of these changes made to\n",
    "            ## pandas settings are local to with statement.\n",
    "            #with pd.option_context('display.max_rows', None,\n",
    "            #                       'display.max_columns', None,\n",
    "            #                       'display.precision', 3,\n",
    "            #                       'display.float_format', '{:,.1f}'.format,\n",
    "            #                       ):\n",
    "            #    next\n",
    "            #    display(subj_gb.pivot_table(f'{qtype}','HypSizePercent',['SUL name','CTT_ES'])[[['BitVise.dot',it] for it in cols_order]])\n",
    "            #    display(subj_gb)\n",
    "            \n",
    "            subj_pvt = subj_gb.pivot_table(f'{qtype}',['CTT_ES'],'HypSizePercent').sort_values(by=list(new_dps))\n",
    "            subj_pvt = subj_pvt/subj_pvt.max().max()\n",
    "            heatmap_cost=sns.heatmap(subj_pvt,\n",
    "                                     #annot=True, fmt=\",.7f\", \n",
    "                                     cmap= sns.cm.rocket_r, linewidth=.5, linecolor='black'\n",
    "                                    )\n",
    "            \n",
    "            #add plot labels, titles and legends\n",
    "            plt.xlabel('Fraction of the SUL learned')\n",
    "            plt.ylabel('')\n",
    "            #plt.legend(title='Testing Technique', loc='lower right')\n",
    "            plt.title(f'Fraction of {qtype} ({sulname})')\n",
    "\n",
    "            \n",
    "            # save line chart\n",
    "            fig = heatmap_cost.get_figure()\n",
    "            os.makedirs(f'img/heatmap/{qtype}/', exist_ok=True)\n",
    "            fig.savefig(f'img/heatmap/{qtype}/'+sulname.replace('.dot',f'_heatmap_{qtype}.jpg'))\n",
    "            fig.clf()\n",
    "            bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
